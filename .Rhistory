# Uses model with price in population
# Assumes we have forecase data in data_list format already
library(readxl)
library(sqldf)
library(shiny)
dir_data <- "C:/Users/K.Lattery/SKIM/Philip Morris - F6886 Advanced modelling update Nov 21/3. Modelling/01 GT IMS top3/Dec13_2022"
#dir_work <- file.path(dir_data, "NoTrend", "Combo_2","RegionOnly_AllPer")
dir_work <- getwd()
dir_work
dir_data <- "C:/Users/K.Lattery/SKIM/Philip Morris - F6886 Advanced modelling update Nov 21/3. Modelling/01 GT IMS top3/Dec13_2022"
dir_work <- file.path(dir_data, "Trend")
dir_base <- "C:/Users/K.Lattery/SKIM/Philip Morris - 3. Prework/3 final data"
#data_tag <- file.path(dir_data, "RW_agg_wpromo_PanRussia.rds") # Pan Russia
data_tag <- file.path(dir_data, "data_list_AR_IMSTop3_wpromo_wtier_combo.rds") # Pan Russia
data_list <- readRDS(data_tag) # Use list of data rather than prepping here
#############################
data_list$promo[] <- 0  # REMOVE ALL PROMOS
############################
model_pars <- readRDS(file.path(dir_work,"result_optim_att_sku_IMSTop3_3per_newprior4_notrend.rds"))
###################################################
# 5. Forecasts
##################################################
maxexp_u_whatif<- function(sim_pop_one, mu_self, mu_whatif, morph_rowtocol, morph_receive, mult_self_b, mult_from_b, P_sku){
# morph_receive is just col_max(morph_rowtocol) item receives morphing
exp_util <- mult_self_b * exp(mu_self + sim_pop_one) # vector mult
exp_util_whatif <- exp(mu_whatif + sim_pop_one)
for (i in 1:P_sku){
if (morph_receive[i] >= .99){
# max_morph <- max(morph_rowtocol[,i] * exp_util_from) # Max from items morphing into i
exp_util[i] <- max(exp_util[i],
mult_from_b[i] * max(morph_rowtocol[,i] * exp_util_whatif) +
(1-mult_from_b[i]) * exp_util[i])
}
}
return(exp_util)
}
log_w0 <- function(index_binary, x){
return(index_binary * log(x + 1.0000000001 - index_binary));
#index = 1 returns log(x), index = 0 returns 0
}
col_max <- function(x){
result <- apply(x, 2, max)
return(result)
}
row_max <- function(x){
result <- apply(x, 1, max)
return(result)
}
# data transforms
log_price <- data_list$price
log_dist <- data_list$dist
log_aware <- data_list$aware
for (i in 1:data_list$N_regions){
for (j in 1:data_list$N_periods){
log_price[i,j,] <- log_w0(data_list$skus_bin[i,j,], data_list$price[i,j,] * .01);
log_dist[i,j,] <- log_w0(data_list$skus_bin[i,j,], data_list$dist[i,j,] * 10);
log_aware[i,j,] <-  log(data_list$aware[i, j,] + .05) - log(1.05);
}
}
morph_rowtocol <- list()
for (j in 1:data_list$N_periods){
morph_rowtocol[[j]] <- data_list$morph_rowtocol[j,,]
}
per_new1 <- c(7:66) # Prior stuff
per_new2 <- 66:78 # Forecasts
per_lag1 <- per_new1 - 3
per_lag2 <- rep(66, length(per_new2))
per_new <- c(per_new1, per_new2)
per_lag <- c(per_lag1, per_lag2)
T <- length(per_new)
region <- rep(1, T)
cbind(region, per_lag, per_new)
AR_MNLwSimPop_max <- function(t,
sim_pop_int, sim_pop_price, morph_rowtocol,
share,
b_price, log_price,
b_dist,  log_dist,
b_trend,
int_sku_over, int_sku_npl,
b_promo_exist, b_promo_npl, promo,
b_aware, log_aware,
b_morph_npl_self, b_morph_npl_hyp, b_morph_exist_hyp,
b_channel_exist, b_channel_npl, channel_bin,
per_base, per_lag, per_new,  region,
skus_bin){
npop <- ncol(sim_pop_int)
P_sku <- nrow(sim_pop_int)
p_lag <- per_lag[t]; #lag period for task
p_new <- per_new[t]; # new/forecast period for task
region_t <- region[t];
skus_fore <- skus_bin[region_t, p_new,]; # // skus in new/forecast period: absolute
skus_lag <- skus_bin[region_t, p_lag,]; # // skus in lag period: absolute
skus_lag <- floor(
(skus_bin[region_t, p_lag,] + skus_bin[region_t, p_lag-1,] + skus_bin[region_t, p_lag-2,] + .1)/3
);
skus_over <- skus_fore * skus_lag; # // skus in both periods: relative
skus_npl <- skus_fore - skus_over; #// skus that are new product launches vs lag: relative
mu_int <- (skus_over * int_sku_over) + (skus_npl * int_sku_npl)
b_promo <- (skus_over * b_promo_exist) + (skus_npl * b_promo_npl); # 2 promos
u_global_lag <- mu_int + b_trend * (p_lag - per_base) +
log_dist[region_t, p_lag,]  * b_dist   +
promo[region_t, p_lag,]     * b_promo +
log_aware[region_t, p_lag,] * b_aware +
(channel_bin[p_lag,,]      %*% b_channel_exist) * skus_over +
(channel_bin[p_lag,,]      %*% b_channel_npl)   * skus_npl;
u_global_fore <- mu_int + b_trend * (p_new - per_base) +
log_dist[region_t, p_new,]  * b_dist   +
promo[region_t, p_new,]     * b_promo +
log_aware[region_t, p_new,] * b_aware +
(channel_bin[p_new,,]      %*% b_channel_exist) * skus_over +
(channel_bin[p_new,,]      %*% b_channel_npl)   * skus_npl;
share_lag_over <- (share[region_t, p_lag,] * skus_over)/sum(share[region_t, p_lag,] * skus_over);
check <- data.frame(data_list$codes, skus_over, skus_npl, share_lag_over,
mu_int = mu_int,
b_dist = b_dist,
u_dist = log_dist[region_t, p_new,]  * b_dist,
u_promo = promo[region_t, p_new,]     * b_promo,
u_aware = log_aware[region_t, p_new,] * b_aware,
u_global_lag = u_global_lag, u_global_fore = u_global_fore)
#///////////////////
#  // Simulations
#////////////////////
#  // Declare some storage
task_prob_sum_new <- rep(0,P_sku);
task_prob_sum_lag <- rep(0,P_sku);
#sim_share_fore <- rep(0,P_sku);
#sim_share_lag <- rep(0,P_sku);
#vector[P_sku] U_final;
#vector[P_sku] pred_new;
#vector[P_sku] exp_util; // placeholder for e^U calcs
#// Forecast
#morph_rowtocol_clean <- diag_post_multiply(morph_rowtocol[p_new,,], skus_fore); #//  Remove any skus that no longer exist
morph_rowtocol_clean <- morph_rowtocol[p_new,,] %*% diag(skus_fore); #//  Remove any skus that no longer exist
#// util of sku @ price, dist of sku morphing into
u_global_whatif <- int_sku_over +
b_trend * (p_new - per_base) +
#log_aware[region_t, p_new,] * b_aware +
channel_bin[p_new,,]      %*% b_channel_exist +
(morph_rowtocol_clean %*% log_dist[region_t, p_new,]) * b_dist;
mu_whatif <- row_max(morph_rowtocol_clean) * u_global_whatif;
mu_whatif[134]
look <- data.frame(data_list$codes, skus_npl, mu_whatif, b_dist, log_dist = log_dist[region_t, p_new,], log_dist_use = (morph_rowtocol_clean %*% log_dist[region_t, p_new,]) )
#colnames(morph_rowtocol_clean) <- codes
morph_receive <- col_max(morph_rowtocol_clean); #// column sums 0/1
morph_npl <- morph_receive * skus_npl;
morph_exist <- morph_receive * (1-skus_npl);
mult_self_b <- (skus_fore - morph_npl) + morph_npl * b_morph_npl_self;
mult_from_b <- morph_npl * b_morph_npl_hyp + morph_exist * b_morph_exist_hyp;
log_price_t <- log_price[region_t, p_new, ]
log_price_t_whatif <- morph_rowtocol_clean %*% log_price_t;
#    check <- data.frame(data_list$codes, int_sku_over,
#                        b_trend * (p_new - per_base),
#                        log_aware[region_t, p_new,] * b_aware,
#                        (morph_rowtocol_clean %*% log_dist[region_t, p_new,]) * b_dist,
#                        mu_whatif, u_global_fore
#    )
#    check68 <- data.frame(data_list$codes, skus_fore, skus_over, skus_npl, int_sku_over, int_sku_npl, morph_receive, morph_npl, morph_exist, mult_self_b, mult_from_b, u_global_fore, u_global_whatif, mu_whatif, log_price_t, log_price_t_whatif)
#write.csv(check68, file.path(dir_work, "check68.csv"))
i <- 1
for (i in 1:npop){
exp_util <- skus_fore * maxexp_u_whatif(
sim_pop_int[,i],
u_global_fore + (sim_pop_price[i] * log_price_t), # change from v4
mu_whatif + (sim_pop_price[i] * log_price_t_whatif), # change from v4
morph_rowtocol_clean, morph_receive,
mult_self_b, mult_from_b, P_sku);
task_prob_sum_new <- task_prob_sum_new + exp_util/sum(exp_util); #// key: sum of shares over pop
}
check_fore <- data.frame(data_list$codes, u_global_fore, u_global_whatif, mu_whatif, mult_self_b, mult_from_b, task_prob_sum_new)
# sum(task_prob_sum_new)
# i <- 4
# look <- cbind(data_list$codes, skus_fore, maxexp_u_whatif_one(
#   sim_pop_int[,i] + (sim_pop_price[i] * log_price_t),
#   u_global_fore, mu_whatif,
#   morph_rowtocol_clean, morph_receive,
#   mult_self_b, mult_from_b, P_sku));
# Repeat for Lag
# Remove any skus not in overlap & that do not contribute to *FORECAST* (morph_self_clean forecast)
#morph_rowtocol_clean <- diag_post_multiply(morph_rowtocol[p_lag,,], skus_over * morph_receive); #// yes this refers to forecast
morph_rowtocol_clean <- morph_rowtocol[p_lag,,] %*% diag(skus_over * morph_receive); #// yes this refers to forecast
look <- morph_rowtocol[p_lag,,]
#colnames(look) <- codes
# util of sku @ price, dist, of sku morphing into
u_global_whatif <- int_sku_over +
b_trend * (p_lag - per_base) +
#log_aware[region_t, p_lag,] * b_aware +
channel_bin[p_lag,,]      %*% b_channel_exist +
(morph_rowtocol_clean %*% log_dist[region_t, p_lag,]) * b_dist;
mu_whatif <- row_max(morph_rowtocol_clean) * u_global_whatif;
#cbind(codes, u_global_lag, row_max(morph_rowtocol_clean), mu_whatif, b_dist, log_dist[region_t, p_lag,], (morph_rowtocol_clean %*% log_dist[region_t, p_lag,]) )
#look <- data.frame(codes, u_global_lag, morph_receive, mu_whatif, b_dist, log_dist[region_t, p_lag,], (morph_rowtocol_clean %*% log_dist[region_t, p_lag,]))
morph_receive <- col_max(morph_rowtocol_clean); #// column sums 0/1
morph_npl <- morph_receive * skus_npl;
morph_exist <- morph_receive * (1-skus_npl);
mult_self_b <- (skus_fore - morph_npl) + morph_npl * b_morph_npl_self;
mult_from_b <- morph_npl * b_morph_npl_hyp + morph_exist * b_morph_exist_hyp;
log_price_t <- log_price[region_t, p_new,]
log_price_t_whatif <- morph_rowtocol_clean %*% log_price_t;
for (i in 1:npop){
exp_util = skus_over * maxexp_u_whatif(
sim_pop_int[,i],
u_global_lag + (sim_pop_price[i] * log_price_t), # change from v4
mu_whatif + (sim_pop_price[i] * log_price_t_whatif), # change from v4
morph_rowtocol_clean, morph_receive,
mult_self_b, mult_from_b, P_sku);
task_prob_sum_lag = task_prob_sum_lag + exp_util/sum(exp_util); #// key: sum of shares over pop
}
#check_lag <- data.frame(u_global_lag, u_global_whatif, mu_whatif, mult_self_b, mult_from_b, task_prob_sum_lag)
#check <- cbind(codes, check_lag, check_fore)
#check <- check_lag - check_fore
# Compute final Utility and LogLikelihood
sim_share_fore <- task_prob_sum_new/npop;
sim_share_lag <- task_prob_sum_lag/npop;
#look <- data.frame(skus_over, share_lag_over, sim_share_fore / (sim_share_lag + 1 - skus_over))
U_final1 <- skus_over * share_lag_over * sim_share_fore / sim_share_lag
U_final2 <- (1-skus_over) * sim_share_fore
lag_ratio <- share_lag_over/(sim_share_lag + 1 - skus_over) # diagnostic want ~1
#check <- data.frame(U_final1, U_final2, skus_over, lag_ratio)
U_final <- skus_over *  sim_share_fore *  share_lag_over/(sim_share_lag + 1 - skus_over) +
(1-skus_over) * sim_share_fore;
pred_new <- U_final/sum(U_final);
#look <- data.frame(skus_over, share_lag_over, U_final1, pred_new)
result <- data.frame(data_list$codes, t = rep(t, P_sku), p_lag = rep(p_lag, P_sku), p_new = rep(p_new,P_sku), skus_over, skus_fore,
lag_share = share[region_t, p_lag,], obs_share = share[region_t, p_new,],
pred_new, sim_share_lag, sim_share_fore, share_lag_over, lag_ratio)
return(result);
}
model_pars$per_base
forecast_all <- do.call(rbind, lapply(1:T, function(t){
result <- AR_MNLwSimPop_max(
t = t,
sim_pop_int = data_list$sku_to_att %*% t(model_pars$sim_pop_int),
sim_pop_price = model_pars$sim_pop_price,
morph_rowtocol = data_list$morph_rowtocol,
share = data_list$share,
log_price = log_price,
b_dist = model_pars$sku_betas_wcode$b_dist, # Changed
log_dist = log_dist,
b_trend = model_pars$sku_betas_wcode$b_trend, # Changed
int_sku_over = data_list$sku_to_att %*% model_pars$b_attributes_over,
int_sku_npl = data_list$sku_to_att %*% model_pars$b_attributes_npl,
b_promo_exist = model_pars$b_promo_exist,
b_promo_npl = model_pars$b_promo_npl,
promo = data_list$promo,
b_aware =  model_pars$b_aware,
log_aware = log_aware,
b_morph_npl_self = model_pars$b_morph_npl_self,
b_morph_npl_hyp = model_pars$b_morph_npl_hyp,
b_morph_exist_hyp = model_pars$b_morph_exist_hyp,
b_channel_exist = model_pars$b_channel_exist,
b_channel_npl = model_pars$b_channel_npl,
channel_bin = data_list$channel_bin,
per_base = model_pars$per_base,
per_lag = per_lag,
per_new = per_new,
region = region,
skus_bin = data_list$skus_bin
)
result <- data.frame(codes = data_list$codes, result,
price_lag = data_list$price[region[t],per_lag[t],],
price_new = data_list$price[region[t],per_new[t],],
dist_lag = data_list$dist[region[t],per_lag[t],],
dist_new = data_list$dist[region[t],per_new[t],]
)
return(result)
}))
forecast_all$obs_share[forecast_all$p_new > 66] <- NA # Don't have shares
forecast_new <- forecast_all[forecast_all$skus_fore == 1 & forecast_all$p_new >=54 & forecast_all$p_new <=66,]
forecast_new <- forecast_all[forecast_all$skus_fore == 1 & forecast_all$p_new >=54,]
kfilter <- (forecast_new$skus_over == 0)
plot(forecast_new$obs_share, forecast_new$sim_share_fore, col = "green") # sim shares
points(forecast_new$obs_share[kfilter], forecast_new$sim_share_fore[kfilter], col = "red") # NPL
plot(forecast_new$obs_share, forecast_new$pred_new, col = "blue")
points(forecast_new$obs_share[kfilter], forecast_new$pred_new[kfilter], col = "red") # NPL
forecast_new <- forecast_all[forecast_all$skus_fore == 1 & forecast_all$p_new >=54,]
holdout <- (forecast_new$p_new > 60)
npl <- (forecast_new$skus_over == 0)
plot(forecast_new$obs_share[!holdout], forecast_new$pred_new[!holdout], col = "green", pch = 16, cex = .45,
xlab = "Observed", ylab = "Predicted")
points(forecast_new$obs_share[!holdout & npl], forecast_new$pred_new[!holdout & npl], col = "green4", pch = 16, cex = .45) # NPL
points(forecast_new$obs_share[holdout], forecast_new$pred_new[holdout], col = "red", pch = 16, cex = .45) # NPL
points(forecast_new$obs_share[holdout & npl], forecast_new$pred_new[holdout & npl], col = "red4", pch = 16, cex = .45) # NPL
legend(x = "bottomright", legend = c("Not Holdout", "Holdout"), fill = c('green', "red"))
dir_work
View(forecast_new)
model_pars$b_promo_npl <- 0
model_pars$b_promo_exist <- 0
forecast_all_1 <- forecast_all
forecast_all <- do.call(rbind, lapply(1:T, function(t){
result <- AR_MNLwSimPop_max(
t = t,
sim_pop_int = data_list$sku_to_att %*% t(model_pars$sim_pop_int),
sim_pop_price = model_pars$sim_pop_price,
morph_rowtocol = data_list$morph_rowtocol,
share = data_list$share,
log_price = log_price,
b_dist = model_pars$sku_betas_wcode$b_dist, # Changed
log_dist = log_dist,
b_trend = model_pars$sku_betas_wcode$b_trend, # Changed
int_sku_over = data_list$sku_to_att %*% model_pars$b_attributes_over,
int_sku_npl = data_list$sku_to_att %*% model_pars$b_attributes_npl,
b_promo_exist = model_pars$b_promo_exist,
b_promo_npl = model_pars$b_promo_npl,
promo = data_list$promo,
b_aware =  model_pars$b_aware,
log_aware = log_aware,
b_morph_npl_self = model_pars$b_morph_npl_self,
b_morph_npl_hyp = model_pars$b_morph_npl_hyp,
b_morph_exist_hyp = model_pars$b_morph_exist_hyp,
b_channel_exist = model_pars$b_channel_exist,
b_channel_npl = model_pars$b_channel_npl,
channel_bin = data_list$channel_bin,
per_base = model_pars$per_base,
per_lag = per_lag,
per_new = per_new,
region = region,
skus_bin = data_list$skus_bin
)
result <- data.frame(codes = data_list$codes, result,
price_lag = data_list$price[region[t],per_lag[t],],
price_new = data_list$price[region[t],per_new[t],],
dist_lag = data_list$dist[region[t],per_lag[t],],
dist_new = data_list$dist[region[t],per_new[t],]
)
return(result)
}))
forecast_all$obs_share[forecast_all$p_new > 66] <- NA # Don't have shares
plot(forecast_all$pred_new, forecast_all_1$pred_new)
write.csv(forecast_new, file = file.path(dir_work, "forecast_new_60_3per_newpriors4_direct.csv"), row.names = FALSE)
write.csv(model_pars$sku_to_attwcode, file = file.path(dir_work, "sku_to_att.csv"))
write.csv(data_list$sku_to_att, file = file.path(dir_work, "sku_to_att.csv"))
# Combine Regional and Pan Russia
library(readxl)
library(sqldf)
library(reshape2)
library(readxl)
#dir <- "C:/Users/K.Lattery/SKIM/Philip Morris - F6886 Advanced modelling update Nov 21/2. Data/1 from PMI SP/1 Historical data/GT IMS top3/UpdateFeb22"
dir <- "C:/Users/K.Lattery/SKIM/Philip Morris - F6886 Advanced modelling update Nov 21/2. Data/1 from PMI SP/2 NPLS data/IMS GT top3/v5 December 13th 2022"
dir_work <- "C:/Users/K.Lattery/SKIM/Philip Morris - F6886 Advanced modelling update Nov 21/3. Modelling/01 GT IMS top3/Dec13_2022"
dir_master <- "C:/Users/K.Lattery/SKIM/Philip Morris - 3. Prework/3 final data"
# Masterfile key and conjoint utilities
#source("C:/Users/K.Lattery/SKIM/Philip Morris - F6643 Data Fusion Reestimation I Sept 21/3. Estimation/Global_Files.R")
#name_to_code <- data.frame(read_xlsx(file.path(dir_master, "F4251 Data Masterfile_3.2.xlsm"), range = "KEY!G1:H1848"))
name_to_code <- data.frame(read_xlsx(file.path(dir_master, "PMI_masterfile.xlsx"), range = "SKUs!A1:D1000"))
name_to_code <- name_to_code[!is.na(name_to_code[,1]),c(1,4)]
att_decompose <- readRDS(file.path(dir_master,"02 Modelling/EvokedwAtts","sku_att_all3.rds"))
# Masterfile key and conjoint utilities
#source("C:/Users/K.Lattery/SKIM/Philip Morris - F6643 Data Fusion Reestimation I Sept 21/3. Estimation/Global_Files.R")
#name_to_code <- data.frame(read_xlsx(file.path(dir_master, "F4251 Data Masterfile_3.2.xlsm"), range = "KEY!G1:H1848"))
name_to_code <- data.frame(read_xlsx(file.path(dir_master, "PMI_masterfile.xlsx"), range = "SKUs!A1:D1000"))
View(name_to_code)
name_to_code <- name_to_code[!is.na(name_to_code[,1]),c(1,4)]
View(name_to_code)
write.csv(name_to_code, file.path(dir_work, "name_to_code.csv"), row.names = FALSE)
# libraries
library(shiny)
library(tidyverse)
library(dplyr)
library(reshape2)
library(shinycssloaders)
library(shinythemes)
library(DT)
library(tidyr)
source("https://raw.githubusercontent.com/klattery/Unspoken/master/Attraction_Conversion_Design_Generator_20SET20_kl3.R")
source("https://raw.githubusercontent.com/klattery/Unspoken/master/UnspokenDesign_RShiny2.R")
shinyApp(ui,server)
# libraries
library(shiny)
library(tidyverse)
library(dplyr)
library(reshape2)
library(shinycssloaders)
library(shinythemes)
library(DT)
library(tidyr)
source("https://raw.githubusercontent.com/klattery/Unspoken/master/Attraction_Conversion_Design_Generator_20SET20_kl3.R")
source("https://raw.githubusercontent.com/klattery/Unspoken/master/UnspokenDesign_RShiny2.R")
shinyApp(ui,server)
